..
.. Copyright 2019 is-land
..
.. Licensed under the Apache License, Version 2.0 (the "License");
.. you may not use this file except in compliance with the License.
.. You may obtain a copy of the License at
..
..     http://www.apache.org/licenses/LICENSE-2.0
..
.. Unless required by applicable law or agreed to in writing, software
.. distributed under the License is distributed on an "AS IS" BASIS,
.. WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
.. See the License for the specific language governing permissions and
.. limitations under the License.
..

.. _rest-workers:

Worker
======

`Worker <https://kafka.apache.org/intro>`__ is core of running
connectors for ohara. It provides a simple but powerful system to
distribute and execute connectors on different nodes. The performance of
connectors depends on the scale of worker cluster. For example, you can
assign the number of task when creating connector. If there is only 3
nodes within your worker cluster and you specify 6 tasks for your
connector, the tasks of you connectors still be deployed on 3 nodes.
That is to say, the connector can’t get more resources to execute.

Worker is based on :ref:`Broker <rest-brokers>`, hence you have to create broker
cluster first. Noted that a broker cluster can be used by multi worker
clusters. BTW, worker cluster will pre-allocate a lot of topics on
broker cluster, and the pre-created topics CAN’T be reused by different
worker clusters.

The properties which can be set by user are shown below.

#. name (**string**) — cluster name
#. group (**string**) — cluster group
#. imageName (**string**) — docker image
#. brokerClusterKey (**Object**) — the broker cluster used to store data generated by this worker cluster

   - brokerClusterKey.group (**option(string)**) — the group of cluster
   - brokerClusterKey.name (**string**) — the name of cluster

  .. note::
    the following forms are legal as well. 1) {"name": "n"} and 2) "n". Both forms are converted to
    {"group": "default", "name": "n"}

#. clientPort (**int**) — worker client port
#. jmxPort (**int**) — worker jmx port
#. freePorts (**Array(int)**) — thr ports you want to pre-bind for the connectors. If your connectors want
                                to build a service on a port which is available to external nodes, you have to
                                define the free ports for your worker cluster so as to make Configurator pre-bind
                                the ports on your worker cluster. Otherwise, your connectors is disable to build service
                                on the port of worker cluster and be connected by external node.
#. group.id (**string**) — the id of worker stored in broker cluster
#. config.storage.topic (**string**) — a internal topic used to store connector configuration
#. config.storage.replication.factor (**int**) — number of replications for config topic
#. offset.storage.topic (**string**) — a internal topic used to store connector offset
#. offset.storage.partitions (**int**) — number of partitions for offset topic
#. offset.storage.replication.factor (**int**) — number of replications for offset topic
#. status.storage.topic (**string**) — a internal topic used to store connector status
#. status.storage.partitions (**int**) — number of partitions for status topic
#. status.storage.replication.factor (**int**) — number of replications for status topic
#. pluginKeys (**array(object)**) — the “primary key” of jars which contain your connectors
                                 You can require worker cluster to load the jars stored in ohara if you want to run custom connectors
                                 on the worker cluster. see :ref:`Files APIs <rest-files>` for uploading jars to ohara. The files which
                                 are deployed to worker must be uber jars - it must include all dependencies exclude for ohara stuff.
#. sharedJarKeys (**array(object)**) — those jars is deployed on the root classpath so all connectors are able to load them.
    .. note::
      #. When you implement the Ohara connector, you must use the File API upload connector jar file
         to worker.

      #. If your jdbc source connector need to use the third party jar file (such oracle
         jdbc jar file), you must use the File API upload jar file then setting sharedJarKeys
         to create the worker API.

#. nodeNames (**array(string)**) — the nodes running the worker process

   The following information are updated by Ohara.

#. aliveNodes (**array(string)**) — the nodes that host the running containers of worker

    .. note::
       The group.id, config.storage.topic, offset.storage.topic and status.storage.topic
       must be unique in broker cluster. Don’t reuse them in same broker
       cluster. Dispatching above unique resources to two worker cluster
       will pollute the data. Of course, ohara do a quick failure for this
       dumb case. However, it is not a quick failure when you are using raw
       kafka rather than ohara. Please double check what you configure!

.. _rest-workers-create:

create a worker properties
--------------------------

*POST /v0/workers*

Example Request
  .. code-block:: json

    {
      "name": "wk",
      "nodeNames": ["node00"],
      "brokerClusterKey": "bk"
    }

Example Response
  .. code-block:: json

    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982566359,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:$|version|",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 33333,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }

.. _rest-workers-list:

list all workers clusters
-------------------------

*GET /v0/workers*

Example Response
  .. code-block:: json

    [
      {
        "brokerClusterKey": {
          "group": "default",
          "name": "bk00"
        },
        "name": "wk00",
        "offset.storage.partitions": 1,
        "xms": 2048,
        "routes": {},
        "config.storage.topic": "b8dadc3de21048fa927335b8f",
        "sharedJarKeys": [],
        "lastModified": 1578982566359,
        "tags": {},
        "xmx": 2048,
        "imageName": "oharastream/connect-worker:$|version|",
        "offset.storage.topic": "346b839ea3e74387ab1eea409",
        "status.storage.replication.factor": 1,
        "group.id": "af4b4d49234a4848bb90fb452",
        "offset.storage.replication.factor": 1,
        "aliveNodes": [],
        "pluginKeys": [],
        "status.storage.partitions": 1,
        "freePorts": [],
        "jmxPort": 33333,
        "config.storage.partitions": 1,
        "clientPort": 45127,
        "config.storage.replication.factor": 1,
        "group": "default",
        "nodeNames": [
          "node00"
        ],
        "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
      }
    ]


update broker cluster properties
--------------------------------

*PUT /v0/workers/$name?group=$group*

.. note::
   If the required worker (group, name) was not exists, we will try to use this request as POST

Example Request
  .. code-block:: json

    {
      "jmxPort": 7777
    }

Example Response
  .. code-block:: json

    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982765738,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:$|version|",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 7777,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }

delete a worker properties
--------------------------

*DELETE /v0/workers/$name?group=$group*

You cannot delete properties of an non-stopped worker cluster.
We will use the default value as the query parameter "?group=" if you don't specify it.

Example Response
  ::

     204 NoContent

  .. note::
     It is ok to delete an nonexistent worker cluster, and the response is
     204 NoContent.

.. _rest-workers-get:

get a worker cluster
--------------------

*GET /v0/workers/$name?group=$group*

We will use the default value as the query parameter "?group=" if you don't specify it.

Example Response
  .. code-block:: json

    {
      "brokerClusterKey": {
        "group": "default",
        "name": "bk00"
      },
      "name": "wk00",
      "offset.storage.partitions": 1,
      "xms": 2048,
      "routes": {},
      "config.storage.topic": "b8dadc3de21048fa927335b8f",
      "sharedJarKeys": [],
      "lastModified": 1578982765738,
      "tags": {},
      "xmx": 2048,
      "imageName": "oharastream/connect-worker:$|version|",
      "offset.storage.topic": "346b839ea3e74387ab1eea409",
      "status.storage.replication.factor": 1,
      "group.id": "af4b4d49234a4848bb90fb452",
      "offset.storage.replication.factor": 1,
      "aliveNodes": [],
      "pluginKeys": [],
      "status.storage.partitions": 1,
      "freePorts": [],
      "jmxPort": 7777,
      "config.storage.partitions": 1,
      "clientPort": 45127,
      "config.storage.replication.factor": 1,
      "group": "default",
      "nodeNames": [
        "node00"
      ],
      "status.storage.topic": "1cdca943f0b945bc892ebe9a7"
    }


start a worker cluster
----------------------

*PUT /v0/workers/$name/start?group=$group*

We will use the default value as the query parameter "?group=" if you don't specify it.

Example Response
  ::

    202 Accepted

  .. note::
     You should use :ref:`Get worker cluster <rest-workers-get>` to fetch up-to-date status

stop a worker cluster
---------------------

Gracefully stopping a running worker cluster.

*PUT /v0/workers/$name/stop?group=$group[&force=true]*

We will use the default value as the query parameter "?group=" if you don't specify it.

Query Parameters
  #. force (**boolean**) — true if you don’t want to wait the graceful shutdown
     (it can save your time but may damage your data).

Example Response
  ::

    202 Accepted

  .. note::
     You should use :ref:`Get worker cluster <rest-workers-get>` to fetch up-to-date status


add a new node to a running worker cluster
------------------------------------------

*PUT /v0/workers/$name/$nodeName?group=$group*

We will use the default value as the query parameter "?group=" if you don't specify it.

If you want to extend a running worker cluster, you can add a node to
share the heavy loading of a running worker cluster. However, the
balance is not triggered at once. By the way, moving a task to another
idle node needs to **stop** task first. Don’t worry about the temporary
lower throughput when balancer is running.

remove a node from a running worker cluster
-------------------------------------------

*DELETE /v0/workers/$name/$nodeName?group=$group*

We will use the default value as the query parameter "?group=" if you don't specify it.

If your budget is limited, you can decrease the number of nodes running
worker cluster. BUT, removing a node from a running worker cluster
invoke a lot of task move, and it will decrease the throughput of your
connector.

Example Response
  ::

     204 NoContent

  .. note::
     It is ok to delete an nonexistent worker node, and the response is
     204 NoContent.

